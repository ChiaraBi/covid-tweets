{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summary_all periods.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#notebook to download the csv of edges and nodes of a given network\n",
        "import os\n",
        "import requests \n",
        "import time\n",
        "import string\n",
        "import networkx as nx\n",
        "import itertools\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.corpus import wordnet as wn #importing it\n",
        "from nltk.stem.wordnet import WordNetLemmatizer #importing wordnet lemmatizer\n",
        "from nltk import pos_tag #part-of-speech-tagger\n",
        "from collections import defaultdict #defaultdict returns default value for non-existant keys you try to  access based on the function you passed in the constructor\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRcCylkZqDPi",
        "outputId": "1f276ac2-d067-4422-98b2-a24dac9c11b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(df):       #extract the text from the tweets and RT\n",
        "                            #works ONLY on .csv file\n",
        "  list_strings = []\n",
        "  for index in range(len(df)):\n",
        "    if index % 1000 == 0:\n",
        "      print(str(index)+' / '+str(len(df)))\n",
        "    text = df.loc[index]['text']                          #if it is nor trucated nor a RT  i take \"text\"\n",
        "    string = -1\n",
        "    if (df.loc[index,\"truncated\"] == True):                 #if it is trucated I take \"extended_tweet\"\n",
        "        string = df.loc[index,\"extended_tweet\"]\n",
        "    if type(df.loc[index,\"retweeted_status\"]) != float:     #if it is a RT I take retweeted_status\n",
        "        string = df.loc[index,\"retweeted_status\"]\n",
        "    if type(string) == str :\n",
        "        if(re.search('full_text\\':(.+?)https',string) != None):     #if I find \"full_text\"\n",
        "          s = re.search('full_text\\':(.+?)https',string).group(1)\n",
        "        if(re.search('text\\':(.+?)https',string)!= None):\n",
        "          s = re.search('text\\':(.+?)https',string).group(1)\n",
        "        else: \n",
        "          continue\n",
        "        list_strings.append(s)\n",
        "        #print(s)         \n",
        "    else:\n",
        "      list_strings.append(text)\n",
        "      #print(text)\n",
        "      \n",
        "\n",
        "  return list_strings"
      ],
      "metadata": {
        "id": "CGa_FVVGqDSJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning, lemmatising and pos tagging tweets\n",
        "\n",
        "nltk.download('words')\n",
        "WORDS = set(nltk.corpus.words.words()) #the last two lines serve to download the corpus of standard English language words\n",
        "nltk.download('stopwords') #downloading stopwords\n",
        "STOP_WORDS = set(nltk.corpus.stopwords.words(\"english\")) #taking the stop words from English language\n",
        "nltk.download('wordnet') #downloading wordnet\n",
        "nltk.download('averaged_perceptron_tagger') #downloading tagger\n",
        "tag_map = defaultdict(lambda : wn.NOUN) #here we define that wn.NOUN is the default value for the dict\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "\n",
        "def lemma_pos_cleaner(tweet):\n",
        "\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) # remove mentions\n",
        "    tweet = re.sub(\"#[A-Za-z0-9]+\", \"\",tweet) # remove hashtags\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) # remove http links\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = str.lower(tweet) #to lowercase \n",
        "    tweet = re.sub(\"'\",\" \",tweet) # remove aphostrophe\n",
        "\n",
        "    #basically we use pos_tag function on tokens that we get by applying wordpunct tokenization\n",
        "    #to tweet (it separates all the words and symbols)\n",
        "    #then we pass the token along with it's wordnet pos value that we get from the tag_map dictionary (noun, adjective, verb or adverb) to the lemma function (the WordNetLemmatizer())\n",
        "    lemma_function = WordNetLemmatizer()\n",
        "    tweet = \" \".join(lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in nltk.pos_tag(nltk.wordpunct_tokenize(tweet))) #lemmatize\n",
        "  \n",
        "\n",
        "    # francesco: I removed also all 2 letters words and added specific words, words that appears frequently but are discarded because they are not in the english language\n",
        "    SPECIFIC_WORDS = ['virus', 'coronavirus', 'covid19', 'covid', 'trump', 'hubei', 'beijing', 'xinjiang', 'jinping', 'korea', 'xinhua', 'india', 'taiwan','johnson','singapore', 'africa', 'japanese', 'france', 'asian', 'australia', 'french', 'asia', 'leishenshan', 'british', 'qingdao', 'fauci', 'america',  'california', 'sichuan', 'malaysia', 'huawei','thailand', 'shandong', 'italy', 'philippines', 'germany', 'facebook', 'african', 'shenzhen', 'tokyo', 'russian','uygur', '5g', 'pompeo', 'vietnam', 'australian', 'cambodia', 'zhejiang', 'yunnan', 'guangdong', 'korean', 'iran', 'washington']\n",
        "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) if (w in WORDS or w in SPECIFIC_WORDS) and len(w)>2 and w not in STOP_WORDS ) #remove stop words\n",
        "   \n",
        "    return tweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0LDoYVqDUh",
        "outputId": "8b6ff527-7e43-426f-c9f1-d78ad7b5bb26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frequency_dictionary(df):\n",
        "  unique_words = {}\n",
        "\n",
        "  for row in df:\n",
        "    for word in row.split():\n",
        "      #if the word is encountered for the first time add to dict as key and set its value to 0\n",
        "      unique_words.setdefault(word,0)\n",
        "      #increase the value (i.e the count) of the word by 1 every time it is encountered\n",
        "      unique_words[word] += 1\n",
        "\n",
        "  return unique_words"
      ],
      "metadata": {
        "id": "MAfOr8vR4P88"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "period = ''  # _JanFeb2020, _MarchApril2021, _SeptOct2020"
      ],
      "metadata": {
        "id": "o-GUlzAVOwk_"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "China = pd.read_csv('/content/China'+period+'.csv')\n",
        "USA = pd.read_csv('/content/USA'+period+'.csv')\n",
        "China_USA = pd.read_csv('/content/China&USA'+period+'.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suPdLaUx1Ct8",
        "outputId": "4f3c8a52-4f73-4e32-bd4e-f36387f204d8"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (34,35,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of tweets:\n",
        "print('China: ', len(China))\n",
        "print('USA: ', len(USA))\n",
        "print('China&USA: ', len(China_USA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeO9nxO6Br3x",
        "outputId": "93ae6a80-159c-4574-aa95-4170658858c7"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  9350\n",
            "USA:  19865\n",
            "China&USA:  29215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_China = extract_text(China)\n",
        "text_USA = extract_text(USA)\n",
        "text_China_USA = extract_text(China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WI3Rz9T1Cxo",
        "outputId": "b7217578-4e0a-4a07-fc5b-47f82d4e323c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 4876\n",
            "1000 / 4876\n",
            "2000 / 4876\n",
            "3000 / 4876\n",
            "4000 / 4876\n",
            "0 / 7519\n",
            "1000 / 7519\n",
            "2000 / 7519\n",
            "3000 / 7519\n",
            "4000 / 7519\n",
            "5000 / 7519\n",
            "6000 / 7519\n",
            "7000 / 7519\n",
            "0 / 12395\n",
            "1000 / 12395\n",
            "2000 / 12395\n",
            "3000 / 12395\n",
            "4000 / 12395\n",
            "5000 / 12395\n",
            "6000 / 12395\n",
            "7000 / 12395\n",
            "8000 / 12395\n",
            "9000 / 12395\n",
            "10000 / 12395\n",
            "11000 / 12395\n",
            "12000 / 12395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text_China = [lemma_pos_cleaner(txt) for txt in text_China]\n",
        "cleaned_text_USA = [lemma_pos_cleaner(txt) for txt in text_USA]\n",
        "cleaned_text_China_USA = [lemma_pos_cleaner(txt) for txt in text_China_USA]\n",
        "\n",
        "print('China:')\n",
        "print(cleaned_text_China[0:10])\n",
        "print()\n",
        "print('USA:')\n",
        "print(cleaned_text_USA[0:10])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(cleaned_text_China_USA[0:10])"
      ],
      "metadata": {
        "id": "6q4JI_jV1C2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac66ca9d-ccf2-4b7d-f83d-b9a1f5da5ad7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "['talk university challenge china face deal misconception people medium watch', 'spring always bring along lively saturate sea colorful bloom flower look collection flower blossom across china enjoy upcoming new season', 'mean carnival brazil year one samba school take inspiration china', 'china world make great stride track infectious disease take unexpected turn make hard track', 'fake news story case covid lead protest evacuation people', 'transmission outside china graphic', 'world health organization announce lead team international expert currently china', 'outside china confirm case novel covid half cruise ship dock japan rest scatter among country mostly asia', 'five cargo aircraft airway head city beijing shanghai carry ton medical supply gratis include million mask hand send epidemic prevention supply purchase china government', 'case miss jinping chair lead body meeting covid control']\n",
            "\n",
            "USA:\n",
            "['shameful attack bus carry evacuee china coronavirus outbreak', 'china hubei say people province prison system also infect coronavirus', 'china coronavirus outbreak late update', 'china foreign journalist coronavirus death climb', 'china coronavirus outbreak late update', 'least people china die spread country', 'aid agency warn patient china run drug amid coronavirus', 'china revoke press credential three wall street journal coronavirus opinion piece deem racist late', 'least people china report recover coronavirus survivor recall ordeal', 'concern china mass surveillance system use combat spread coronavirus']\n",
            "\n",
            "China&USA:\n",
            "['talk university challenge china face deal misconception people medium watch', 'spring always bring along lively saturate sea colorful bloom flower look collection flower blossom across china enjoy upcoming new season', 'mean carnival brazil year one samba school take inspiration china', 'china world make great stride track infectious disease take unexpected turn make hard track', 'fake news story case covid lead protest evacuation people', 'transmission outside china graphic', 'world health organization announce lead team international expert currently china', 'outside china confirm case novel covid half cruise ship dock japan rest scatter among country mostly asia', 'five cargo aircraft airway head city beijing shanghai carry ton medical supply gratis include million mask hand send epidemic prevention supply purchase china government', 'case miss jinping chair lead body meeting covid control']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCiw0q7t4UER",
        "outputId": "50f4caa6-3887-45ea-bfdf-de2e19ad0a3b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  5699\n",
            "USA:  6476\n",
            "China&USA:  8185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent words\n",
        "print('China')\n",
        "print([key for key in freq_dict_China.keys() if freq_dict_China[key]>200])\n",
        "print()\n",
        "print('USA')\n",
        "print([key for key in freq_dict_USA.keys() if freq_dict_USA[key]>400])\n",
        "print()\n",
        "print('China&USA')\n",
        "print([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]>600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y29OU9Cd5Auv",
        "outputId": "f662f9eb-fc27-4d6e-c713-250d6d667b4f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "['china', 'covid', 'novel', 'case', 'coronavirus', 'say', 'new', 'hospital', 'vaccine', 'outbreak', 'people', 'report', 'patient', 'fight', 'country', 'health', 'day', 'city', 'province', 'year', 'confirm', 'first', 'world', 'epidemic', 'death', 'live', 'national', 'medical', 'president', 'amid', 'million', 'hubei', 'one', 'take', 'support', 'virus', 'control', 'battle', 'help', 'test', 'see', 'pandemic', 'official', 'infection', 'show', 'work', 'number', 'effort', 'global', 'two', 'late', 'expert', 'receive', 'make', 'total', 'central', 'time', 'watch', 'accord', 'use', 'measure', 'state', 'across', 'high', 'discharge', 'bring', 'development', 'infect']\n",
            "\n",
            "USA\n",
            "['coronavirus', 'covid', 'china', 'say', 'vaccine', 'case', 'new', 'outbreak', 'virus', 'test', 'trump', 'death', 'people', 'report', 'president', 'health', 'spread', 'first', 'state', 'country', 'day', 'world', 'pandemic', 'million', 'positive', 'rise', 'late', 'year', 'infection', 'city', 'global', 'official', 'week', 'two', 'hit', 'get', 'one', 'take', 'house', 'johnson', 'amid', 'month', 'use', 'hospital', 'could', 'trial', 'may', 'travel', 'due', 'confirm', 'government', 'toll', 'japan', 'quarantine', 'accord', 'ship', 'fear', 'record', 'risk', 'make', 'cruise', 'number', 'white', 'india', 'help', 'second', 'high', 'plan', 'study', 'surge']\n",
            "\n",
            "China&USA\n",
            "['china', 'covid', 'coronavirus', 'say', 'vaccine', 'case', 'new', 'outbreak', 'people', 'report', 'virus', 'health', 'death', 'test', 'president', 'novel', 'country', 'trump', 'first', 'hospital', 'day', 'world', 'spread', 'year', 'city', 'state', 'million', 'pandemic', 'patient', 'confirm', 'fight', 'infection', 'one', 'take', 'positive', 'amid', 'late', 'official', 'global', 'two', 'rise', 'week', 'national', 'get', 'help', 'province', 'use', 'hit', 'number', 'see', 'make', 'accord', 'medical', 'show', 'work', 'month', 'government', 'live', 'time', 'travel', 'epidemic', 'high', 'house', 'control', 'second', 'due', 'hubei', 'johnson', 'trial', 'may', 'could']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# less frequent words"
      ],
      "metadata": {
        "id": "9oHPXYbpINWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# less frequent words:\n",
        "print('Less frequent China: ', len([key for key in freq_dict_China.keys() if freq_dict_China[key]<10]))\n",
        "print('More frequent China: ', len([key for key in freq_dict_China.keys() if freq_dict_China[key]>=10]))\n",
        "less_frequent_words_China = [key for key in freq_dict_China.keys() if freq_dict_China[key]<10]\n",
        "\n",
        "print('Less frequent USA: ', len([key for key in freq_dict_USA.keys() if freq_dict_USA[key]<10]))\n",
        "print('More frequent USA:', len([key for key in freq_dict_USA.keys() if freq_dict_USA[key]>=10]))\n",
        "less_frequent_words_USA = [key for key in freq_dict_USA.keys() if freq_dict_USA[key]<10]\n",
        "\n",
        "print('Less frequent China&USA: ', len([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]<10]))\n",
        "print('More frequent China&USA: ', len([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]>=10]))\n",
        "less_frequent_words_China_USA = [key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]<10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgiQzaHD5zAb",
        "outputId": "538b7080-5d86-4c20-8667-df087f1ff7d1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Less frequent China:  4155\n",
            "More frequent China:  1544\n",
            "Less frequent USA:  4287\n",
            "More frequent USA: 2189\n",
            "Less frequent China&USA:  5344\n",
            "More frequent China&USA:  2841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# discard less frequent words\n",
        "cleaned_mostfreq_text_China = cleaned_text_China.copy()\n",
        "for txt in range(len(cleaned_mostfreq_text_China)):\n",
        "  if txt % 1000 == 0:\n",
        "    print(txt, '/',len(cleaned_mostfreq_text_China))\n",
        "  for word in less_frequent_words_China:\n",
        "    if word in cleaned_mostfreq_text_China[txt].split():\n",
        "      cleaned_mostfreq_text_China[txt] = cleaned_mostfreq_text_China[txt].replace(word, '')\n",
        "      cleaned_mostfreq_text_China[txt] = \" \".join(cleaned_mostfreq_text_China[txt].split())\n",
        "\n",
        "cleaned_mostfreq_text_USA = cleaned_text_USA.copy()\n",
        "for txt in range(len(cleaned_mostfreq_text_USA)):\n",
        "  if txt % 1000 == 0:\n",
        "    print(txt, '/',len(cleaned_mostfreq_text_USA))\n",
        "  for word in less_frequent_words_USA:\n",
        "    if word in cleaned_mostfreq_text_USA[txt].split():\n",
        "      cleaned_mostfreq_text_USA[txt] = cleaned_mostfreq_text_USA[txt].replace(word, '')\n",
        "      cleaned_mostfreq_text_USA[txt] = \" \".join(cleaned_mostfreq_text_USA[txt].split())\n",
        "\n",
        "cleaned_mostfreq_text_China_USA = cleaned_text_China_USA.copy()\n",
        "for txt in range(len(cleaned_mostfreq_text_China_USA)):\n",
        "  if txt % 1000 == 0:\n",
        "    print(txt, '/',len(cleaned_mostfreq_text_China_USA))\n",
        "  for word in less_frequent_words_China_USA:\n",
        "    if word in cleaned_mostfreq_text_China_USA[txt].split():\n",
        "      cleaned_mostfreq_text_China_USA[txt] = cleaned_mostfreq_text_China_USA[txt].replace(word, '')\n",
        "      cleaned_mostfreq_text_China_USA[txt] = \" \".join(cleaned_mostfreq_text_China_USA[txt].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmlqtzHp6lh8",
        "outputId": "defefe9e-8a9d-43e9-ffbd-f23ac3e5e913"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 9268\n",
            "1000 / 9268\n",
            "2000 / 9268\n",
            "3000 / 9268\n",
            "4000 / 9268\n",
            "5000 / 9268\n",
            "6000 / 9268\n",
            "7000 / 9268\n",
            "8000 / 9268\n",
            "9000 / 9268\n",
            "0 / 19860\n",
            "1000 / 19860\n",
            "2000 / 19860\n",
            "3000 / 19860\n",
            "4000 / 19860\n",
            "5000 / 19860\n",
            "6000 / 19860\n",
            "7000 / 19860\n",
            "8000 / 19860\n",
            "9000 / 19860\n",
            "10000 / 19860\n",
            "11000 / 19860\n",
            "12000 / 19860\n",
            "13000 / 19860\n",
            "14000 / 19860\n",
            "15000 / 19860\n",
            "16000 / 19860\n",
            "17000 / 19860\n",
            "18000 / 19860\n",
            "19000 / 19860\n",
            "0 / 29128\n",
            "1000 / 29128\n",
            "2000 / 29128\n",
            "3000 / 29128\n",
            "4000 / 29128\n",
            "5000 / 29128\n",
            "6000 / 29128\n",
            "7000 / 29128\n",
            "8000 / 29128\n",
            "9000 / 29128\n",
            "10000 / 29128\n",
            "11000 / 29128\n",
            "12000 / 29128\n",
            "13000 / 29128\n",
            "14000 / 29128\n",
            "15000 / 29128\n",
            "16000 / 29128\n",
            "17000 / 29128\n",
            "18000 / 29128\n",
            "19000 / 29128\n",
            "20000 / 29128\n",
            "21000 / 29128\n",
            "22000 / 29128\n",
            "23000 / 29128\n",
            "24000 / 29128\n",
            "25000 / 29128\n",
            "26000 / 29128\n",
            "27000 / 29128\n",
            "28000 / 29128\n",
            "29000 / 29128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_mostfreq_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_mostfreq_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_mostfreq_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KHj5-o57f8y",
        "outputId": "7a5203b9-f1af-4645-9d83-05fcf213648a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  1573\n",
            "USA:  2208\n",
            "China&USA:  2862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Network"
      ],
      "metadata": {
        "id": "1davLfA3HNV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_China = pd.DataFrame.from_dict(freq_dict_China, orient='index').reset_index()\n",
        "df_China.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China.reset_index(inplace=True)\n",
        "df_China.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_USA = pd.DataFrame.from_dict(freq_dict_USA, orient='index').reset_index()\n",
        "df_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_USA.reset_index(inplace=True)\n",
        "df_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_China_USA = pd.DataFrame.from_dict(freq_dict_China_USA, orient='index').reset_index()\n",
        "df_China_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China_USA.reset_index(inplace=True)\n",
        "df_China_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "print('China')\n",
        "print(df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA')\n",
        "print(df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA')\n",
        "print(df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxPPnevj890b",
        "outputId": "5a44551e-ce1d-4a68-82b9-a7c4403d1105"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "           Word  Count\n",
            "0         china   5087\n",
            "1         covid   1749\n",
            "2         novel   1402\n",
            "3          case   1359\n",
            "4   coronavirus   1264\n",
            "5           say   1158\n",
            "6           new   1128\n",
            "7      hospital   1014\n",
            "8       vaccine    960\n",
            "9      outbreak    877\n",
            "10       people    757\n",
            "11       report    705\n",
            "12      patient    685\n",
            "13        fight    683\n",
            "14      country    640\n",
            "15       health    638\n",
            "16          day    594\n",
            "17         city    572\n",
            "18     province    571\n",
            "19         year    552\n",
            "20      confirm    542\n",
            "21        first    510\n",
            "22        world    492\n",
            "23     epidemic    460\n",
            "24        death    446\n",
            "25         live    443\n",
            "26     national    442\n",
            "27      medical    440\n",
            "28    president    434\n",
            "29         amid    396\n",
            "\n",
            "USA\n",
            "           Word  Count\n",
            "0   coronavirus   7552\n",
            "1         covid   7261\n",
            "2         china   5151\n",
            "3           say   3474\n",
            "4       vaccine   3383\n",
            "5          case   2560\n",
            "6           new   2489\n",
            "7      outbreak   1619\n",
            "8         virus   1536\n",
            "9          test   1424\n",
            "10        trump   1396\n",
            "11        death   1340\n",
            "12       people   1305\n",
            "13       report   1268\n",
            "14    president   1245\n",
            "15       health   1229\n",
            "16       spread   1117\n",
            "17        first   1035\n",
            "18        state    973\n",
            "19      country    915\n",
            "20          day    870\n",
            "21        world    862\n",
            "22     pandemic    857\n",
            "23      million    792\n",
            "24     positive    759\n",
            "25         rise    745\n",
            "26         late    661\n",
            "27         year    653\n",
            "28    infection    648\n",
            "29         city    630\n",
            "\n",
            "China&USA\n",
            "           Word  Count\n",
            "0         china  10238\n",
            "1         covid   9010\n",
            "2   coronavirus   8816\n",
            "3           say   4632\n",
            "4       vaccine   4343\n",
            "5          case   3919\n",
            "6           new   3617\n",
            "7      outbreak   2496\n",
            "8        people   2062\n",
            "9        report   1973\n",
            "10        virus   1884\n",
            "11       health   1867\n",
            "12        death   1786\n",
            "13         test   1752\n",
            "14    president   1679\n",
            "15        novel   1585\n",
            "16      country   1555\n",
            "17        trump   1549\n",
            "18        first   1545\n",
            "19     hospital   1529\n",
            "20          day   1464\n",
            "21        world   1354\n",
            "22       spread   1313\n",
            "23         year   1205\n",
            "24         city   1202\n",
            "25        state   1189\n",
            "26      million   1187\n",
            "27     pandemic   1169\n",
            "28      patient   1076\n",
            "29      confirm   1032\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_China = freq_dict_China.keys()  \n",
        "keys_USA = freq_dict_USA.keys()  \n",
        "keys_China_USA = freq_dict_China_USA.keys()  "
      ],
      "metadata": {
        "id": "zHmEpbLtr46D"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(cleaned_text):\n",
        "  network = {}\n",
        "  #connect the word that appear in the same tweets\n",
        "  for row in cleaned_text:\n",
        "    combined_list = [word for word in str.split(row)]\n",
        "    #for pair in itertools.product(combined_list, combined_list):\n",
        "    #print(combined_list)\n",
        "    for pair in itertools.product(combined_list, combined_list):\n",
        "          #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
        "          if pair[0]!=pair[1] and not(pair[::-1] in network):\n",
        "              network.setdefault(pair,0)\n",
        "              network[pair] += 1 \n",
        "  network_df = pd.DataFrame.from_dict(network, orient=\"index\")\n",
        "  network_df.columns = [\"weight\"]\n",
        "  network_df.sort_values(by=\"weight\",inplace=True, ascending=False)\n",
        "  return network, network_df"
      ],
      "metadata": {
        "id": "nUAWB6lT1DAd"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_China, network_df_China = create_network(cleaned_mostfreq_text_China)\n",
        "network_USA, network_df_USA = create_network(cleaned_mostfreq_text_USA)\n",
        "network_China_USA, network_df_China_USA = create_network(cleaned_mostfreq_text_China_USA)"
      ],
      "metadata": {
        "id": "7vR_r37vAGye"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(network_df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(network_df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(network_df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMWDZua_b-l",
        "outputId": "328bea9e-eb6f-42c1-ce7b-bc3d018428a8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "                      weight\n",
            "(china, novel)          1025\n",
            "(china, say)             762\n",
            "(new, case)              758\n",
            "(china, coronavirus)     662\n",
            "(confirm, case)          653\n",
            "(china, outbreak)        650\n",
            "(case, report)           632\n",
            "(china, case)            602\n",
            "(vaccine, covid)         586\n",
            "(china, new)             577\n",
            "(patient, hospital)      572\n",
            "(china, fight)           572\n",
            "(china, covid)           547\n",
            "(novel, coronavirus)     499\n",
            "(china, province)        441\n",
            "(report, new)            434\n",
            "(case, death)            432\n",
            "(china, people)          415\n",
            "(epidemic, china)        401\n",
            "(novel, outbreak)        394\n",
            "(china, country)         393\n",
            "(china, support)         385\n",
            "(china, national)        356\n",
            "(year, china)            352\n",
            "(china, hospital)        348\n",
            "(day, china)             343\n",
            "(city, china)            339\n",
            "(case, covid)            333\n",
            "(china, vaccine)         329\n",
            "(china, confirm)         324\n",
            "\n",
            "USA:\n",
            "                         weight\n",
            "(china, coronavirus)       2665\n",
            "(vaccine, covid)           2212\n",
            "(say, covid)               1470\n",
            "(coronavirus, case)        1312\n",
            "(coronavirus, outbreak)    1210\n",
            "(say, coronavirus)         1171\n",
            "(president, trump)         1077\n",
            "(covid, case)              1074\n",
            "(new, covid)               1060\n",
            "(new, coronavirus)         1040\n",
            "(china, outbreak)           945\n",
            "(new, case)                 932\n",
            "(vaccine, say)              921\n",
            "(spread, coronavirus)       807\n",
            "(test, covid)               793\n",
            "(china, case)               763\n",
            "(test, positive)            761\n",
            "(coronavirus, death)        752\n",
            "(china, virus)              748\n",
            "(china, say)                734\n",
            "(china, new)                718\n",
            "(covid, trump)              713\n",
            "(case, report)              637\n",
            "(people, coronavirus)       626\n",
            "(test, coronavirus)         617\n",
            "(coronavirus, health)       614\n",
            "(china, death)              600\n",
            "(covid, president)          597\n",
            "(trump, say)                586\n",
            "(report, covid)             575\n",
            "\n",
            "China&USA:\n",
            "                         weight\n",
            "(china, coronavirus)       3327\n",
            "(vaccine, covid)           2798\n",
            "(covid, say)               1740\n",
            "(new, case)                1690\n",
            "(coronavirus, case)        1603\n",
            "(china, outbreak)          1595\n",
            "(china, say)               1496\n",
            "(coronavirus, outbreak)    1451\n",
            "(case, covid)              1407\n",
            "(china, case)              1365\n",
            "(new, covid)               1307\n",
            "(china, new)               1295\n",
            "(say, coronavirus)         1292\n",
            "(coronavirus, new)         1272\n",
            "(case, report)             1269\n",
            "(president, trump)         1191\n",
            "(china, novel)             1110\n",
            "(say, vaccine)             1102\n",
            "(confirm, case)            1090\n",
            "(report, new)               989\n",
            "(china, virus)              982\n",
            "(covid, test)               917\n",
            "(test, positive)            914\n",
            "(china, covid)              908\n",
            "(china, people)             892\n",
            "(spread, coronavirus)       863\n",
            "(coronavirus, death)        835\n",
            "(case, death)               831\n",
            "(china, death)              817\n",
            "(report, covid)             798\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graph\n"
      ],
      "metadata": {
        "id": "gfvo8x0Ku78D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(network):\n",
        "  up_weighted = []\n",
        "  for edge in network:\n",
        "      #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
        "      up_weighted.append((edge[0],edge[1],network[edge]))\n",
        "      \n",
        "  #print(network)\n",
        "  #print(up_weighted[0:10])\n",
        "  G = nx.Graph()\n",
        "  G.add_weighted_edges_from(up_weighted)\n",
        "  return G"
      ],
      "metadata": {
        "id": "2NGKuSuYAo-K"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_China = get_graph(network_China)\n",
        "G_USA = get_graph(network_USA)\n",
        "G_China_USA = get_graph(network_China_USA)"
      ],
      "metadata": {
        "id": "TbpTF19bBKJq"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print('Nodes: ',len(G_China.nodes()))\n",
        "print('Edges: ',len(G_China.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China))\n",
        "print()\n",
        "print('USA:')\n",
        "print('Nodes: ',len(G_USA.nodes()))\n",
        "print('Edges: ',len(G_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_USA))\n",
        "print()\n",
        "print('China&USA:')\n",
        "print('Nodes: ',len(G_China_USA.nodes()))\n",
        "print('Edges: ',len(G_China_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China_USA))"
      ],
      "metadata": {
        "id": "W178ljb9rM6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82024b94-aa4d-4cb7-fb98-41059bda11ca"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "Nodes:  1572\n",
            "Edges:  155952\n",
            "Is connected:  True\n",
            "\n",
            "USA:\n",
            "Nodes:  2208\n",
            "Edges:  241398\n",
            "Is connected:  True\n",
            "\n",
            "China&USA:\n",
            "Nodes:  2862\n",
            "Edges:  391951\n",
            "Is connected:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PageRank"
      ],
      "metadata": {
        "id": "1LYNr4McLtWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "P6qJVv9vHIr1"
      },
      "outputs": [],
      "source": [
        "# Calculating the pagerank on graph G, teleportation probability here is 0.15 but since the graph is strongly connected we can set it to zero if we want\n",
        "pr_China = nx.algorithms.pagerank(G_China,alpha = 1)\n",
        "pr_China = dict(sorted(pr_China.items(), key=lambda item: item[1],reverse  = True))\n",
        "\n",
        "pr_USA = nx.algorithms.pagerank(G_USA,alpha = 1)\n",
        "pr_USA = dict(sorted(pr_USA.items(), key=lambda item: item[1],reverse  = True))\n",
        "\n",
        "pr_China_USA = nx.algorithms.pagerank(G_China_USA,alpha = 1)\n",
        "pr_China_USA = dict(sorted(pr_China_USA.items(), key=lambda item: item[1],reverse  = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "BcVoAXxqpqLd"
      },
      "outputs": [],
      "source": [
        "def threshold(vector,threshold):\n",
        "\n",
        "  l = [(el,vector[el]) for el in vector if vector[el] >= threshold ]\n",
        "\n",
        "  return pd.DataFrame(l)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_reverse(vector,threshold):\n",
        "\n",
        "  l = [(el,vector[el]) for el in vector if vector[el] < threshold ]\n",
        "\n",
        "  return pd.DataFrame(l)"
      ],
      "metadata": {
        "id": "7-UFIOEJL6bY"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cUhquN72cI6",
        "outputId": "ac9d6ce6-b11d-4ec2-f894-9f7ee53312fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  714\n",
            "\n",
            "first:\n",
            "              0         1\n",
            "0         china  0.048910\n",
            "1         covid  0.015820\n",
            "2         novel  0.014042\n",
            "3          case  0.013749\n",
            "4           say  0.013300\n",
            "5   coronavirus  0.011654\n",
            "6           new  0.011312\n",
            "7      hospital  0.009882\n",
            "8      outbreak  0.008687\n",
            "9        people  0.008277\n",
            "10      vaccine  0.008052\n",
            "11       report  0.007580\n",
            "12       health  0.007339\n",
            "13      country  0.007219\n",
            "14      patient  0.006854\n",
            "15          day  0.006802\n",
            "16         city  0.006615\n",
            "17     province  0.006574\n",
            "18        fight  0.006523\n",
            "19         year  0.006340\n",
            "20      confirm  0.005904\n",
            "21        world  0.005461\n",
            "22        first  0.005375\n",
            "23     national  0.005041\n",
            "24      medical  0.004920\n",
            "25     epidemic  0.004892\n",
            "26        death  0.004846\n",
            "27          one  0.004540\n",
            "28    president  0.004418\n",
            "29        hubei  0.004358\n",
            "\n",
            "last:\n",
            "                0         1\n",
            "684        access  0.000309\n",
            "685          task  0.000309\n",
            "686        single  0.000309\n",
            "687        reform  0.000308\n",
            "688         thank  0.000308\n",
            "689          heat  0.000308\n",
            "690        german  0.000308\n",
            "691         mayor  0.000308\n",
            "692         birth  0.000308\n",
            "693        farmer  0.000307\n",
            "694         panic  0.000307\n",
            "695         scale  0.000307\n",
            "696      governor  0.000307\n",
            "697  contribution  0.000306\n",
            "698       ancient  0.000306\n",
            "699    restaurant  0.000306\n",
            "700          port  0.000306\n",
            "701      relation  0.000305\n",
            "702       british  0.000304\n",
            "703           ten  0.000304\n",
            "704          clot  0.000304\n",
            "705          must  0.000303\n",
            "706    department  0.000303\n",
            "707          bank  0.000302\n",
            "708        french  0.000302\n",
            "709           kit  0.000302\n",
            "710           box  0.000302\n",
            "711         field  0.000301\n",
            "712     necessity  0.000301\n",
            "713        direct  0.000301\n",
            "\n",
            "USA:  669\n",
            "\n",
            "first:\n",
            "              0         1\n",
            "0   coronavirus  0.032653\n",
            "1         covid  0.030115\n",
            "2         china  0.021294\n",
            "3           say  0.018383\n",
            "4       vaccine  0.014874\n",
            "5           new  0.011662\n",
            "6          case  0.011304\n",
            "7         trump  0.008763\n",
            "8      outbreak  0.008149\n",
            "9     president  0.007666\n",
            "10       people  0.007585\n",
            "11        virus  0.007455\n",
            "12       health  0.007155\n",
            "13         test  0.007087\n",
            "14        death  0.006130\n",
            "15       report  0.005771\n",
            "16        first  0.005460\n",
            "17        state  0.005309\n",
            "18      country  0.005210\n",
            "19       spread  0.005171\n",
            "20     pandemic  0.004923\n",
            "21        world  0.004782\n",
            "22          day  0.004740\n",
            "23     positive  0.003924\n",
            "24         year  0.003808\n",
            "25      million  0.003753\n",
            "26     official  0.003690\n",
            "27        house  0.003531\n",
            "28         week  0.003530\n",
            "29          one  0.003455\n",
            "\n",
            "last:\n",
            "                  0         1\n",
            "639           plant  0.000317\n",
            "640            play  0.000317\n",
            "641          inside  0.000317\n",
            "642        identify  0.000317\n",
            "643          though  0.000315\n",
            "644        critical  0.000314\n",
            "645           mount  0.000314\n",
            "646         compare  0.000314\n",
            "647  misinformation  0.000314\n",
            "648          reveal  0.000313\n",
            "649     investigate  0.000312\n",
            "650          policy  0.000312\n",
            "651      administer  0.000311\n",
            "652          really  0.000311\n",
            "653        threaten  0.000310\n",
            "654          sector  0.000310\n",
            "655          little  0.000307\n",
            "656             bed  0.000307\n",
            "657            dock  0.000306\n",
            "658            poor  0.000306\n",
            "659           black  0.000306\n",
            "660       isolation  0.000306\n",
            "661        security  0.000305\n",
            "662        traveler  0.000305\n",
            "663        forecast  0.000305\n",
            "664           anger  0.000305\n",
            "665          huawei  0.000304\n",
            "666         weekend  0.000304\n",
            "667           spark  0.000304\n",
            "668            real  0.000300\n",
            "\n",
            "China&USA:  678\n",
            "\n",
            "first:\n",
            "              0         1\n",
            "0         china  0.029770\n",
            "1   coronavirus  0.024643\n",
            "2         covid  0.024496\n",
            "3           say  0.016159\n",
            "4       vaccine  0.012130\n",
            "5          case  0.011533\n",
            "6           new  0.011078\n",
            "7      outbreak  0.008029\n",
            "8        people  0.007589\n",
            "9        health  0.006942\n",
            "10    president  0.006395\n",
            "11        trump  0.006136\n",
            "12       report  0.006084\n",
            "13        virus  0.006066\n",
            "14      country  0.005694\n",
            "15         test  0.005632\n",
            "16        death  0.005421\n",
            "17        novel  0.005301\n",
            "18          day  0.005232\n",
            "19        first  0.005231\n",
            "20     hospital  0.004885\n",
            "21        world  0.004885\n",
            "22         year  0.004558\n",
            "23         city  0.004353\n",
            "24     pandemic  0.004217\n",
            "25        state  0.004123\n",
            "26       spread  0.004014\n",
            "27      million  0.003793\n",
            "28          one  0.003694\n",
            "29      patient  0.003546\n",
            "\n",
            "last:\n",
            "              0         1\n",
            "648       front  0.000315\n",
            "649      happen  0.000313\n",
            "650     package  0.000313\n",
            "651   isolation  0.000312\n",
            "652       every  0.000312\n",
            "653       chain  0.000312\n",
            "654         mid  0.000312\n",
            "655     percent  0.000312\n",
            "656       light  0.000311\n",
            "657   available  0.000311\n",
            "658  protection  0.000311\n",
            "659     prepare  0.000310\n",
            "660        boom  0.000310\n",
            "661       speak  0.000309\n",
            "662      tackle  0.000309\n",
            "663    congress  0.000309\n",
            "664  technology  0.000308\n",
            "665    stimulus  0.000308\n",
            "666    previous  0.000305\n",
            "667      strain  0.000304\n",
            "668      review  0.000304\n",
            "669         non  0.000303\n",
            "670     protest  0.000303\n",
            "671    activity  0.000302\n",
            "672       penny  0.000302\n",
            "673        roll  0.000302\n",
            "674    approval  0.000302\n",
            "675    infected  0.000302\n",
            "676      action  0.000301\n",
            "677      suffer  0.000300\n"
          ]
        }
      ],
      "source": [
        "print('China: ', len(threshold(pr_China,0.0003)))\n",
        "print()\n",
        "print('first:')\n",
        "print(threshold(pr_China,0.0003).iloc[:30])\n",
        "print()\n",
        "print('last:')\n",
        "print(threshold(pr_China,0.0003).iloc[684:])\n",
        "print()\n",
        "print('USA: ', len(threshold(pr_USA,0.0003)))\n",
        "print()\n",
        "print('first:')\n",
        "print(threshold(pr_USA,0.0003).iloc[:30])\n",
        "print()\n",
        "print('last:')\n",
        "print(threshold(pr_USA,0.0003).iloc[639:])\n",
        "print()\n",
        "print('China&USA: ', len(threshold(pr_China_USA,0.0003)))\n",
        "print()\n",
        "print('first:')\n",
        "print(threshold(pr_China_USA,0.0003).iloc[:30])\n",
        "print()\n",
        "print('last:')\n",
        "print(threshold(pr_China_USA,0.0003).iloc[648:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIqlZ2nZ9qKW"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "gVbC8VFA9pgw"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,1))   # ngram range can be changed to obtain measures regarding n grams instead of single words\n",
        "\n",
        "X_China = tfidf.fit_transform(cleaned_mostfreq_text_China).toarray()    # entry (i,j) if Tfidf measure of word_list[j] in document i\n",
        "word_list_China = tfidf.get_feature_names_out()\n",
        "\n",
        "X_USA = tfidf.fit_transform(cleaned_mostfreq_text_USA).toarray()\n",
        "word_list_USA = tfidf.get_feature_names_out()\n",
        "\n",
        "X_China_USA = tfidf.fit_transform(cleaned_mostfreq_text_China_USA).toarray()\n",
        "word_list_China_USA = tfidf.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "8k8fcvKX-yah"
      },
      "outputs": [],
      "source": [
        "tfidf_df_China = pd.DataFrame(X_China,columns = word_list_China)\n",
        "\n",
        "tfidf_df_USA = pd.DataFrame(X_USA,columns = word_list_USA)\n",
        "\n",
        "tfidf_df_China_USA = pd.DataFrame(X_China_USA,columns = word_list_China_USA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "MUr9_93WCKsj"
      },
      "outputs": [],
      "source": [
        "tfidf_word_measure_China = np.mean(tfidf_df_China,axis = 0)\n",
        "tfidf_word_measure_China = tfidf_word_measure_China.sort_values(ascending = False)\n",
        "tfidf_word_measure_USA = np.mean(tfidf_df_USA,axis = 0)\n",
        "tfidf_word_measure_USA = tfidf_word_measure_USA.sort_values(ascending = False)\n",
        "tfidf_word_measure_China_USA = np.mean(tfidf_df_China_USA,axis = 0)\n",
        "tfidf_word_measure_China_USA = tfidf_word_measure_China_USA.sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(tfidf_word_measure_China[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(tfidf_word_measure_USA[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(tfidf_word_measure_China_USA[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dknv21f3XimF",
        "outputId": "880e96e6-bc8f-414a-e3d4-7509caec4494"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "china          0.057393\n",
            "covid          0.032344\n",
            "case           0.029077\n",
            "novel          0.027626\n",
            "coronavirus    0.027115\n",
            "new            0.025339\n",
            "vaccine        0.022859\n",
            "hospital       0.022712\n",
            "say            0.020808\n",
            "outbreak       0.019470\n",
            "report         0.017295\n",
            "fight          0.016957\n",
            "patient        0.016629\n",
            "people         0.015936\n",
            "confirm        0.014500\n",
            "watch          0.014347\n",
            "health         0.014288\n",
            "country        0.014000\n",
            "day            0.013577\n",
            "live           0.013453\n",
            "province       0.012905\n",
            "first          0.012837\n",
            "city           0.012793\n",
            "death          0.012317\n",
            "year           0.012240\n",
            "world          0.011623\n",
            "epidemic       0.011616\n",
            "amid           0.011082\n",
            "medical        0.011039\n",
            "president      0.010959\n",
            "dtype: float64\n",
            "\n",
            "USA:\n",
            "coronavirus    0.049972\n",
            "covid          0.048809\n",
            "china          0.041930\n",
            "vaccine        0.031179\n",
            "case           0.028555\n",
            "say            0.027612\n",
            "new            0.026551\n",
            "report         0.017860\n",
            "death          0.017719\n",
            "outbreak       0.017477\n",
            "virus          0.016571\n",
            "test           0.016000\n",
            "spread         0.014537\n",
            "people         0.013405\n",
            "health         0.013065\n",
            "trump          0.012863\n",
            "first          0.012383\n",
            "late           0.012190\n",
            "president      0.011938\n",
            "day            0.011102\n",
            "million        0.010978\n",
            "state          0.010971\n",
            "rise           0.010859\n",
            "country        0.010299\n",
            "world          0.009807\n",
            "positive       0.009792\n",
            "pandemic       0.009256\n",
            "infection      0.009202\n",
            "hit            0.008676\n",
            "confirm        0.008295\n",
            "dtype: float64\n",
            "\n",
            "China&USA:\n",
            "china          0.045033\n",
            "coronavirus    0.043029\n",
            "covid          0.042957\n",
            "case           0.027942\n",
            "vaccine        0.027795\n",
            "new            0.025423\n",
            "say            0.024511\n",
            "outbreak       0.017291\n",
            "report         0.017268\n",
            "death          0.015774\n",
            "virus          0.013796\n",
            "people         0.013548\n",
            "test           0.013425\n",
            "health         0.013033\n",
            "first          0.012092\n",
            "novel          0.011916\n",
            "hospital       0.011775\n",
            "spread         0.011651\n",
            "day            0.011465\n",
            "president      0.011090\n",
            "country        0.011073\n",
            "late           0.010992\n",
            "million        0.010481\n",
            "trump          0.010241\n",
            "confirm        0.010155\n",
            "world          0.009889\n",
            "state          0.009267\n",
            "infection      0.009075\n",
            "city           0.009014\n",
            "patient        0.008786\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reduced graph"
      ],
      "metadata": {
        "id": "4nkLA8k0LB7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# less frequent words:\n",
        "less_important_words_China = [key for key in list(threshold_reverse(pr_China,0.0003)[0])]\n",
        "\n",
        "less_important_words_USA = [key for key in list(threshold_reverse(pr_USA,0.0003)[0])]\n",
        "\n",
        "less_important_words_China_USA = [key for key in list(threshold_reverse(pr_China_USA,0.0003)[0])]"
      ],
      "metadata": {
        "id": "6ndwCL9oLpDA"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discard less frequent words\n",
        "cleaned_mostimp_text_China = cleaned_mostfreq_text_China.copy()\n",
        "for txt in range(len(cleaned_mostimp_text_China)):\n",
        "  if txt % 1000 == 0:\n",
        "    print(txt, '/',len(cleaned_mostimp_text_China))\n",
        "  for word in less_important_words_China:\n",
        "    if word in cleaned_mostimp_text_China[txt].split():\n",
        "      cleaned_mostimp_text_China[txt] = cleaned_mostimp_text_China[txt].replace(word, '')\n",
        "      cleaned_mostimp_text_China[txt] = \" \".join(cleaned_mostimp_text_China[txt].split())\n",
        "\n",
        "cleaned_mostimp_text_USA = cleaned_mostfreq_text_USA.copy()\n",
        "for txt in range(len(cleaned_mostimp_text_USA)):\n",
        "  if txt % 1000 == 0:\n",
        "    print(txt, '/',len(cleaned_mostimp_text_USA))\n",
        "  for word in less_important_words_USA:\n",
        "    if word in cleaned_mostimp_text_USA[txt].split():\n",
        "      cleaned_mostimp_text_USA[txt] = cleaned_mostimp_text_USA[txt].replace(word, '')\n",
        "      cleaned_mostimp_text_USA[txt] = \" \".join(cleaned_mostimp_text_USA[txt].split())\n",
        "\n",
        "cleaned_mostimp_text_China_USA = cleaned_mostfreq_text_China_USA.copy()\n",
        "for txt in range(len(cleaned_mostimp_text_China_USA)):\n",
        "  if txt % 1000 == 0:\n",
        "    print(txt, '/',len(cleaned_mostimp_text_China_USA))\n",
        "  for word in less_important_words_China_USA:\n",
        "    if word in cleaned_mostimp_text_China_USA[txt].split():\n",
        "      cleaned_mostimp_text_China_USA[txt] = cleaned_mostimp_text_China_USA[txt].replace(word, '')\n",
        "      cleaned_mostimp_text_China_USA[txt] = \" \".join(cleaned_mostimp_text_China_USA[txt].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d00353-568f-438a-d2bf-f7dd5c8d78a9",
        "id": "D8L4ETxALpDB"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 9268\n",
            "1000 / 9268\n",
            "2000 / 9268\n",
            "3000 / 9268\n",
            "4000 / 9268\n",
            "5000 / 9268\n",
            "6000 / 9268\n",
            "7000 / 9268\n",
            "8000 / 9268\n",
            "9000 / 9268\n",
            "0 / 19860\n",
            "1000 / 19860\n",
            "2000 / 19860\n",
            "3000 / 19860\n",
            "4000 / 19860\n",
            "5000 / 19860\n",
            "6000 / 19860\n",
            "7000 / 19860\n",
            "8000 / 19860\n",
            "9000 / 19860\n",
            "10000 / 19860\n",
            "11000 / 19860\n",
            "12000 / 19860\n",
            "13000 / 19860\n",
            "14000 / 19860\n",
            "15000 / 19860\n",
            "16000 / 19860\n",
            "17000 / 19860\n",
            "18000 / 19860\n",
            "19000 / 19860\n",
            "0 / 29128\n",
            "1000 / 29128\n",
            "2000 / 29128\n",
            "3000 / 29128\n",
            "4000 / 29128\n",
            "5000 / 29128\n",
            "6000 / 29128\n",
            "7000 / 29128\n",
            "8000 / 29128\n",
            "9000 / 29128\n",
            "10000 / 29128\n",
            "11000 / 29128\n",
            "12000 / 29128\n",
            "13000 / 29128\n",
            "14000 / 29128\n",
            "15000 / 29128\n",
            "16000 / 29128\n",
            "17000 / 29128\n",
            "18000 / 29128\n",
            "19000 / 29128\n",
            "20000 / 29128\n",
            "21000 / 29128\n",
            "22000 / 29128\n",
            "23000 / 29128\n",
            "24000 / 29128\n",
            "25000 / 29128\n",
            "26000 / 29128\n",
            "27000 / 29128\n",
            "28000 / 29128\n",
            "29000 / 29128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_mostimp_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_mostimp_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_mostimp_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a59de80-00b4-4375-8419-d5fe3978a432",
        "id": "X2ObCNtJLpDB"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  752\n",
            "USA:  710\n",
            "China&USA:  766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_China = pd.DataFrame.from_dict(freq_dict_China, orient='index').reset_index()\n",
        "df_China.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China.reset_index(inplace=True)\n",
        "df_China.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_USA = pd.DataFrame.from_dict(freq_dict_USA, orient='index').reset_index()\n",
        "df_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_USA.reset_index(inplace=True)\n",
        "df_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_China_USA = pd.DataFrame.from_dict(freq_dict_China_USA, orient='index').reset_index()\n",
        "df_China_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China_USA.reset_index(inplace=True)\n",
        "df_China_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "print('China')\n",
        "print(df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA')\n",
        "print(df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA')\n",
        "print(df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613b1609-717f-4c6a-8a2f-120eed3e43b1",
        "id": "DfrViAqzNnb9"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "           Word  Count\n",
            "0         china   5087\n",
            "1         covid   1749\n",
            "2         novel   1402\n",
            "3          case   1359\n",
            "4   coronavirus   1264\n",
            "5           say   1157\n",
            "6           new   1128\n",
            "7      hospital   1014\n",
            "8       vaccine    959\n",
            "9      outbreak    877\n",
            "10       people    757\n",
            "11       report    705\n",
            "12      patient    685\n",
            "13        fight    683\n",
            "14      country    639\n",
            "15       health    638\n",
            "16          day    594\n",
            "17         city    572\n",
            "18     province    571\n",
            "19         year    552\n",
            "20      confirm    542\n",
            "21        first    510\n",
            "22        world    492\n",
            "23     epidemic    460\n",
            "24        death    446\n",
            "25         live    443\n",
            "26     national    442\n",
            "27      medical    440\n",
            "28    president    434\n",
            "29         amid    396\n",
            "\n",
            "USA\n",
            "           Word  Count\n",
            "0   coronavirus   7549\n",
            "1         covid   7261\n",
            "2         china   5151\n",
            "3           say   3473\n",
            "4       vaccine   3383\n",
            "5          case   2560\n",
            "6           new   2489\n",
            "7      outbreak   1619\n",
            "8         virus   1539\n",
            "9          test   1423\n",
            "10        trump   1396\n",
            "11        death   1340\n",
            "12       people   1305\n",
            "13       report   1264\n",
            "14    president   1244\n",
            "15       health   1229\n",
            "16       spread   1117\n",
            "17        first   1034\n",
            "18        state    973\n",
            "19      country    913\n",
            "20          day    870\n",
            "21        world    862\n",
            "22     pandemic    857\n",
            "23      million    792\n",
            "24     positive    756\n",
            "25         rise    745\n",
            "26         late    661\n",
            "27         year    653\n",
            "28    infection    648\n",
            "29         city    630\n",
            "\n",
            "China&USA\n",
            "           Word  Count\n",
            "0         china  10237\n",
            "1         covid   9010\n",
            "2   coronavirus   8811\n",
            "3           say   4628\n",
            "4       vaccine   4342\n",
            "5          case   3919\n",
            "6           new   3617\n",
            "7      outbreak   2496\n",
            "8        people   2062\n",
            "9        report   1964\n",
            "10        virus   1887\n",
            "11       health   1864\n",
            "12        death   1786\n",
            "13         test   1752\n",
            "14    president   1679\n",
            "15        novel   1585\n",
            "16      country   1549\n",
            "17        trump   1549\n",
            "18        first   1545\n",
            "19     hospital   1529\n",
            "20          day   1458\n",
            "21        world   1354\n",
            "22       spread   1313\n",
            "23         year   1203\n",
            "24         city   1202\n",
            "25        state   1189\n",
            "26      million   1187\n",
            "27     pandemic   1169\n",
            "28      patient   1076\n",
            "29      confirm   1032\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_China = freq_dict_China.keys()  \n",
        "keys_USA = freq_dict_USA.keys()  \n",
        "keys_China_USA = freq_dict_China_USA.keys()  "
      ],
      "metadata": {
        "id": "Q52SCkkKNncF"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_China, network_df_China = create_network(cleaned_mostimp_text_China)\n",
        "network_USA, network_df_USA = create_network(cleaned_mostimp_text_USA)\n",
        "network_China_USA, network_df_China_USA = create_network(cleaned_mostimp_text_China_USA)"
      ],
      "metadata": {
        "id": "bPn3tfv7NncF"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(network_df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(network_df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(network_df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e64ece8-4b35-40d4-f62e-1861044cd7a2",
        "id": "MVggBElVNncF"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "                      weight\n",
            "(china, novel)          1025\n",
            "(china, say)             762\n",
            "(new, case)              758\n",
            "(china, coronavirus)     662\n",
            "(confirm, case)          653\n",
            "(china, outbreak)        650\n",
            "(case, report)           632\n",
            "(china, case)            602\n",
            "(vaccine, covid)         585\n",
            "(china, new)             577\n",
            "(china, fight)           572\n",
            "(patient, hospital)      572\n",
            "(china, covid)           547\n",
            "(novel, coronavirus)     499\n",
            "(china, province)        441\n",
            "(report, new)            434\n",
            "(case, death)            432\n",
            "(china, people)          415\n",
            "(epidemic, china)        401\n",
            "(novel, outbreak)        394\n",
            "(china, country)         393\n",
            "(china, support)         385\n",
            "(china, national)        356\n",
            "(year, china)            352\n",
            "(china, hospital)        348\n",
            "(day, china)             343\n",
            "(city, china)            339\n",
            "(case, covid)            333\n",
            "(china, vaccine)         329\n",
            "(china, confirm)         324\n",
            "\n",
            "USA:\n",
            "                         weight\n",
            "(china, coronavirus)       2665\n",
            "(vaccine, covid)           2212\n",
            "(say, covid)               1470\n",
            "(coronavirus, case)        1312\n",
            "(coronavirus, outbreak)    1209\n",
            "(say, coronavirus)         1171\n",
            "(president, trump)         1076\n",
            "(covid, case)              1074\n",
            "(new, covid)               1060\n",
            "(new, coronavirus)         1040\n",
            "(china, outbreak)           945\n",
            "(new, case)                 932\n",
            "(vaccine, say)              921\n",
            "(spread, coronavirus)       807\n",
            "(test, covid)               792\n",
            "(china, case)               763\n",
            "(test, positive)            758\n",
            "(coronavirus, death)        752\n",
            "(china, virus)              748\n",
            "(china, say)                734\n",
            "(china, new)                718\n",
            "(covid, trump)              713\n",
            "(case, report)              635\n",
            "(people, coronavirus)       626\n",
            "(test, coronavirus)         616\n",
            "(coronavirus, health)       614\n",
            "(china, death)              600\n",
            "(covid, president)          596\n",
            "(trump, say)                586\n",
            "(report, covid)             575\n",
            "\n",
            "China&USA:\n",
            "                         weight\n",
            "(china, coronavirus)       3327\n",
            "(vaccine, covid)           2797\n",
            "(covid, say)               1739\n",
            "(new, case)                1690\n",
            "(coronavirus, case)        1603\n",
            "(china, outbreak)          1595\n",
            "(china, say)               1493\n",
            "(coronavirus, outbreak)    1450\n",
            "(case, covid)              1407\n",
            "(china, case)              1365\n",
            "(new, covid)               1307\n",
            "(china, new)               1295\n",
            "(say, coronavirus)         1292\n",
            "(coronavirus, new)         1272\n",
            "(case, report)             1262\n",
            "(president, trump)         1191\n",
            "(china, novel)             1110\n",
            "(say, vaccine)             1101\n",
            "(confirm, case)            1090\n",
            "(report, new)               989\n",
            "(china, virus)              982\n",
            "(covid, test)               917\n",
            "(test, positive)            912\n",
            "(china, covid)              908\n",
            "(china, people)             892\n",
            "(spread, coronavirus)       863\n",
            "(coronavirus, death)        835\n",
            "(case, death)               831\n",
            "(china, death)              817\n",
            "(report, covid)             794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(network):\n",
        "  up_weighted = []\n",
        "  for edge in network:\n",
        "      #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
        "      up_weighted.append((edge[0],edge[1],network[edge]))\n",
        "      \n",
        "  #print(network)\n",
        "  #print(up_weighted[0:10])\n",
        "  G = nx.Graph()\n",
        "  G.add_weighted_edges_from(up_weighted)\n",
        "  return G"
      ],
      "metadata": {
        "id": "fmQTFAb3NncF"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_China = get_graph(network_China)\n",
        "G_USA = get_graph(network_USA)\n",
        "G_China_USA = get_graph(network_China_USA)"
      ],
      "metadata": {
        "id": "zNrH5boVNncF"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print('Nodes: ',len(G_China.nodes()))\n",
        "print('Edges: ',len(G_China.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China))\n",
        "print()\n",
        "print('USA:')\n",
        "print('Nodes: ',len(G_USA.nodes()))\n",
        "print('Edges: ',len(G_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_USA))\n",
        "print()\n",
        "print('China&USA:')\n",
        "print('Nodes: ',len(G_China_USA.nodes()))\n",
        "print('Edges: ',len(G_China_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China_USA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71184d05-c7e5-4120-df15-f3f9cd645bd9",
        "id": "kx5041hFNncF"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "Nodes:  751\n",
            "Edges:  82457\n",
            "Is connected:  True\n",
            "\n",
            "USA:\n",
            "Nodes:  710\n",
            "Edges:  99452\n",
            "Is connected:  True\n",
            "\n",
            "China&USA:\n",
            "Nodes:  766\n",
            "Edges:  125167\n",
            "Is connected:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save edge list"
      ],
      "metadata": {
        "id": "p4SvWlzSfzFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = './edgelist_China_700.csv'\n",
        "nx.write_weighted_edgelist(G_China, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_China_700.csv\n",
        "files.download(\"edgelist_China_700.csv\")\n",
        "\n",
        "filename = './edgelist_USA_700.csv'\n",
        "nx.write_weighted_edgelist(G_USA, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_USA_700.csv\n",
        "files.download(\"edgelist_USA_700.csv\")\n",
        "\n",
        "filename = './edgelist_China_USA_700.csv'\n",
        "nx.write_weighted_edgelist(G_China_USA, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_China_USA_700.csv\n",
        "files.download(\"edgelist_China_USA_700.csv\")"
      ],
      "metadata": {
        "id": "zgmmRGRCrM9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "daa2b1c8-273c-42b4-b8b0-dbac7254e6d7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_eca03a87-7a47-443d-8faf-b6bab5532b94\", \"edgelist_China_700.csv\", 1305415)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e9530dea-29cc-447e-bcb0-1ff772c405a0\", \"edgelist_USA_700.csv\", 1550354)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7cf1df5c-6dd3-481f-8659-802f03cae80c\", \"edgelist_China_USA_700.csv\", 1963268)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create Node List\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nWHLO7AhdwzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nodes(freq_dict, name):\n",
        "  word_nodes = pd.DataFrame.from_dict(freq_dict,orient=\"index\")\n",
        "  word_nodes.reset_index(inplace=True)\n",
        "  word_nodes[\"Label\"] = word_nodes[\"index\"]\n",
        "  word_nodes.rename(columns={\"index\":\"Id\",0:\"delete\"},inplace=True)\n",
        "  word_nodes = word_nodes.drop(columns=['delete'])\n",
        "  nodelist = pd.DataFrame()\n",
        "  nodelist = nodelist.append(word_nodes, ignore_index=True)\n",
        "\n",
        "  nodelist = nodelist.to_csv(\"nodelist_\"+name+\".csv\",index=False)\n",
        "  files.download(\"nodelist_\"+name+\".csv\")\n",
        "  return nodelist, word_nodes"
      ],
      "metadata": {
        "id": "v2GYb2BQFzET"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodelist_China, word_nodes_China = nodes(freq_dict_China,\"China_700\")\n",
        "nodelist_USA, word_nodes_USA = nodes(freq_dict_USA,\"USA_700\")\n",
        "nodelist_China_USA, word_nodes_China_USA = nodes(freq_dict_China_USA,\"China_USA_700\")\n",
        "\n",
        "print('China:')\n",
        "print(word_nodes_China.head())\n",
        "print()\n",
        "print('USA:')\n",
        "print(word_nodes_USA.head())\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(word_nodes_China_USA.head())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "EmQrEHV0F1QY",
        "outputId": "01240680-19e9-426c-ec2d-ce1d3c883a3b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_19a2e2a7-3f60-42f3-b293-c1dec87ad268\", \"nodelist_China_700.csv\", 10375)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_aaf9db84-40ea-4387-8630-a1d89263ca8e\", \"nodelist_USA_700.csv\", 9641)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d4207047-1f0b-40e8-af40-cef069350c11\", \"nodelist_China_USA_700.csv\", 10267)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "            Id        Label\n",
            "0        china        china\n",
            "1        covid        covid\n",
            "2        novel        novel\n",
            "3         case         case\n",
            "4  coronavirus  coronavirus\n",
            "\n",
            "USA:\n",
            "            Id        Label\n",
            "0  coronavirus  coronavirus\n",
            "1        covid        covid\n",
            "2        china        china\n",
            "3          say          say\n",
            "4      vaccine      vaccine\n",
            "\n",
            "China&USA:\n",
            "            Id        Label\n",
            "0        china        china\n",
            "1        covid        covid\n",
            "2  coronavirus  coronavirus\n",
            "3          say          say\n",
            "4      vaccine      vaccine\n",
            "\n"
          ]
        }
      ]
    }
  ]
}